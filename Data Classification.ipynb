{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Classification : K-Nearest Neighbour Classifier and Bayes Classifier with Unimodal Gaussian Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Steel Plates Faults Data Set as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>...</th>\n",
       "      <th>Edges_X_Index</th>\n",
       "      <th>Edges_Y_Index</th>\n",
       "      <th>Outside_Global_Index</th>\n",
       "      <th>LogOfAreas</th>\n",
       "      <th>Log_X_Index</th>\n",
       "      <th>Log_Y_Index</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1325</td>\n",
       "      <td>1339</td>\n",
       "      <td>30207</td>\n",
       "      <td>30238</td>\n",
       "      <td>268</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>25809</td>\n",
       "      <td>79</td>\n",
       "      <td>124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4281</td>\n",
       "      <td>1.1461</td>\n",
       "      <td>1.4914</td>\n",
       "      <td>0.5484</td>\n",
       "      <td>-0.2476</td>\n",
       "      <td>0.7065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>55572</td>\n",
       "      <td>55629</td>\n",
       "      <td>370</td>\n",
       "      <td>48</td>\n",
       "      <td>62</td>\n",
       "      <td>39293</td>\n",
       "      <td>27</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.9194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5682</td>\n",
       "      <td>1.1761</td>\n",
       "      <td>1.7559</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>-0.1703</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1323</td>\n",
       "      <td>1333</td>\n",
       "      <td>68445</td>\n",
       "      <td>68506</td>\n",
       "      <td>330</td>\n",
       "      <td>48</td>\n",
       "      <td>61</td>\n",
       "      <td>33449</td>\n",
       "      <td>90</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.7853</td>\n",
       "      <td>0.8361</td>\n",
       "      <td>-0.2081</td>\n",
       "      <td>0.8861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1324</td>\n",
       "      <td>1333</td>\n",
       "      <td>75642</td>\n",
       "      <td>75681</td>\n",
       "      <td>207</td>\n",
       "      <td>25</td>\n",
       "      <td>39</td>\n",
       "      <td>21354</td>\n",
       "      <td>93</td>\n",
       "      <td>124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.3160</td>\n",
       "      <td>0.9542</td>\n",
       "      <td>1.5911</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>-0.1941</td>\n",
       "      <td>0.5805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1324</td>\n",
       "      <td>1335</td>\n",
       "      <td>97132</td>\n",
       "      <td>97213</td>\n",
       "      <td>594</td>\n",
       "      <td>55</td>\n",
       "      <td>81</td>\n",
       "      <td>61608</td>\n",
       "      <td>93</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7738</td>\n",
       "      <td>1.0414</td>\n",
       "      <td>1.9085</td>\n",
       "      <td>0.8642</td>\n",
       "      <td>-0.1897</td>\n",
       "      <td>0.9806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n",
       "0       1325       1339      30207      30238           268           29   \n",
       "1          1         16      55572      55629           370           48   \n",
       "2       1323       1333      68445      68506           330           48   \n",
       "3       1324       1333      75642      75681           207           25   \n",
       "4       1324       1335      97132      97213           594           55   \n",
       "\n",
       "   Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n",
       "0           31              25809                     79   \n",
       "1           62              39293                     27   \n",
       "2           61              33449                     90   \n",
       "3           39              21354                     93   \n",
       "4           81              61608                     93   \n",
       "\n",
       "   Maximum_of_Luminosity  ...  Edges_X_Index  Edges_Y_Index  \\\n",
       "0                    124  ...         0.4828         1.0000   \n",
       "1                    119  ...         0.3125         0.9194   \n",
       "2                    119  ...         0.2083         1.0000   \n",
       "3                    124  ...         0.3600         1.0000   \n",
       "4                    125  ...         0.2000         1.0000   \n",
       "\n",
       "   Outside_Global_Index  LogOfAreas  Log_X_Index  Log_Y_Index  \\\n",
       "0                   1.0      2.4281       1.1461       1.4914   \n",
       "1                   1.0      2.5682       1.1761       1.7559   \n",
       "2                   1.0      2.5185       1.0000       1.7853   \n",
       "3                   1.0      2.3160       0.9542       1.5911   \n",
       "4                   1.0      2.7738       1.0414       1.9085   \n",
       "\n",
       "   Orientation_Index  Luminosity_Index  SigmoidOfAreas  Class  \n",
       "0             0.5484           -0.2476          0.7065      1  \n",
       "1             0.7368           -0.1703          0.9755      1  \n",
       "2             0.8361           -0.2081          0.8861      1  \n",
       "3             0.7692           -0.1941          0.5805      1  \n",
       "4             0.8642           -0.1897          0.9806      1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SteelPlateFaults-2class.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data of each class from SteelPlateFaults-2class.csv into train data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In class '0'\n",
    "df_0 = df[df[\"Class\"]==0]\n",
    "\n",
    "[X_train_0, X_test_0,X_label_train_0,X_label_test_0] = train_test_split(df_0,\n",
    "                                   df_0['Class'], test_size=0.3,\n",
    "                                   random_state=42, shuffle=True)\n",
    "\n",
    "#In class '1'\n",
    "df_1 = df[df[\"Class\"]==1]\n",
    "\n",
    "[X_train_1, X_test_1,\n",
    "  X_label_train_1,\n",
    "  X_label_test_1] = train_test_split(df_1,\n",
    "                                   df_1['Class'], test_size=0.3,\n",
    "                                   random_state=42, shuffle=True)                            \n",
    "## Joining the training of class 0 and 1\n",
    "# and testing data of class 0 and 1\n",
    "[X_train, X_test, X_label_train,\n",
    " X_label_test] = [X_train_0.append(X_train_1),\n",
    "                  X_test_0.append(X_test_1),\n",
    "                  X_label_train_0.append(X_label_train_1),\n",
    "                  X_label_test_0.append(X_label_test_1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the training and testing data in CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('SteelPlateFaults-2class-train.csv', index=False)\n",
    "X_test.to_csv('SteelPlateFaults-2class-test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the KNN Classifier to classify given dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def knn_classifier(x_train, x_test, x_label_test, x_label_train):\n",
    "    for i in range(1, 6, 2):\n",
    "        knn = KNeighborsClassifier(n_neighbors=i)\n",
    "        knn.fit(x_train, x_label_train)\n",
    "        \n",
    "        # Printing the Accuracies and Confusion matrix for each K\n",
    "        print(' K = {:}'.format(i))\n",
    "        print(' Accuracy : {:.3f}'\n",
    "             .format(knn.score(x_test, x_label_test)))\n",
    "        print(' Confusion Matrix :\\n')\n",
    "        print(confusion_matrix(x_label_test, knn.predict(x_test)),'\\n')\n",
    "        if(i == 5):\n",
    "            return knn.score(x_test, x_label_test)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing the KNN classification technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K = 1\n",
      " Accuracy : 0.869\n",
      " Confusion Matrix :\n",
      "\n",
      "[[ 93  25]\n",
      " [ 19 200]] \n",
      "\n",
      " K = 3\n",
      " Accuracy : 0.896\n",
      " Confusion Matrix :\n",
      "\n",
      "[[ 92  26]\n",
      " [  9 210]] \n",
      "\n",
      " K = 5\n",
      " Accuracy : 0.893\n",
      " Confusion Matrix :\n",
      "\n",
      "[[ 92  26]\n",
      " [ 10 209]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_accuracy_knn = knn_classifier(X_train[list(df)[:-1]], X_test[list(df)[:-1]], X_label_test, X_label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using KNN Classifier after normalizing all the attributes (except class attribute) of SteelPlateFaults-train.csv\n",
    "using Min-Max normalization to transform the data in the range [0-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_normalised = min_max_scaler.fit_transform(X_train)\n",
    "X_train_normalised = pd.DataFrame(X_train_normalised)\n",
    "X_train_normalised.rename(columns={i: list(df)[i] for i in range(len(list(df)))}, inplace=True)\n",
    "X_train_normalised.to_csv('SteelPlateFaults-2class-train-normalised.csv', index=False)\n",
    "\n",
    "# Dropping the tuples having out of bound values\n",
    "# (As compared with the min. and max. from training data)\n",
    "drop_tuple_indexes = set()\n",
    "for i in range(len(list(df))):\n",
    "    for j in X_test.index:\n",
    "        if(X_test[list(X_test)[i]][j] < min_max_scaler.data_min_[i]):\n",
    "            drop_tuple_indexes.add(j)\n",
    "        if(X_test[list(X_test)[i]][j] > min_max_scaler.data_max_[i]):\n",
    "            drop_tuple_indexes.add(j)\n",
    "\n",
    "X_test_normalised = min_max_scaler.fit_transform(X_test.drop(list(drop_tuple_indexes), axis=0))\n",
    "X_test_normalised = pd.DataFrame(X_test_normalised)\n",
    "X_test_normalised.rename(columns={i: list(df)[i] for i in range(len(list(df)))}, inplace=True)\n",
    "X_test_normalised.to_csv('SteelPlateFaults-2class-test-normalised.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Appying the KNN classfication technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K = 1\n",
      " Accuracy : 0.964\n",
      " Confusion Matrix :\n",
      "\n",
      "[[109   7]\n",
      " [  5 208]] \n",
      "\n",
      " K = 3\n",
      " Accuracy : 0.976\n",
      " Confusion Matrix :\n",
      "\n",
      "[[111   5]\n",
      " [  3 210]] \n",
      "\n",
      " K = 5\n",
      " Accuracy : 0.979\n",
      " Confusion Matrix :\n",
      "\n",
      "[[111   5]\n",
      " [  2 211]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_accuracy_knn_normalised = knn_classifier(X_train_normalised[list(df)[:-1]],\n",
    "                                              X_test_normalised[list(df)[:-1]],\n",
    "                                              X_test_normalised['Class'],\n",
    "                                              X_train_normalised['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a Bayes Classifer with given training data\n",
    "and testing on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-4c198a08e707>:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  val = (1/(((2*np.pi)**(d/2))*(np.linalg.det(cov_matrix)**0.5)))\n",
      "<ipython-input-15-4c198a08e707>:10: RuntimeWarning: overflow encountered in exp\n",
      "  val *= np.exp(-0.5*np.dot(np.dot((x - mean).T, np.linalg.inv(cov_matrix)), (x - mean)))\n"
     ]
    }
   ],
   "source": [
    "# Dimension of the training and testing data\n",
    "d = 27\n",
    "\n",
    "# Function to calculate likelihood of a class for given test sample\n",
    "def likelihood(x, mean, cov_matrix):\n",
    "    x = np.array(x)\n",
    "    mean = np.array(mean)\n",
    "    cov_matrix = np.array(cov_matrix)\n",
    "    val = (1/(((2*np.pi)**(d/2))*(np.linalg.det(cov_matrix)**0.5)))\n",
    "    val *= np.exp(-0.5*np.dot(np.dot((x - mean).T, np.linalg.inv(cov_matrix)), (x - mean)))\n",
    "    return val\n",
    "\n",
    "# Priors of each class from the training data\n",
    "prior_0 = list(X_train['Class']).count(0)/len(X_train['Class'])\n",
    "prior_1 = list(X_train['Class']).count(1)/len(X_train['Class'])\n",
    "\n",
    "\n",
    "\n",
    "df_0 = df_0[list(df_0)[:-1]]\n",
    "df_1 = df_1[list(df_1)[:-1]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Mean matrices for each class\n",
    "mean_0 = df_0.mean().to_numpy()\n",
    "mean_1 = df_1.mean().to_numpy()\n",
    "\n",
    "\n",
    "# Covariance matrices for each class\n",
    "cov_matrix_0 = df_0.cov().to_numpy()\n",
    "cov_matrix_1 = df_1.cov().to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "# Predicted test labels\n",
    "X_label_test_predicted = []\n",
    "for i in np.array(X_test[list(X_test)[:-1]]):\n",
    "    likl_0 = likelihood(i, mean_0, cov_matrix_0)\n",
    "    likl_1 = likelihood(i, mean_1, cov_matrix_1)\n",
    "    posterior_0 = (likl_0 * prior_0)/ (likl_0 * prior_0 + likl_1 * prior_1)\n",
    "    posterior_1 = (likl_1 * prior_1)/ (likl_0 * prior_0 + likl_1 * prior_1)\n",
    "    if(posterior_0 > posterior_1):\n",
    "        X_label_test_predicted.append(0)\n",
    "    else:\n",
    "        X_label_test_predicted.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 118]\n",
      " [  0 219]]\n",
      "\n",
      " Accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(X_label_test, X_label_test_predicted))\n",
    "print('\\n Accuracy: %.2f'%(accuracy_score(X_label_test, X_label_test_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tablulating the best results of each Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Classifier  Accuracy\n",
      "0             KNN  0.893175\n",
      "1  KNN Normalised  0.978723\n",
      "2           Bayes  0.649852\n"
     ]
    }
   ],
   "source": [
    "res = pd.DataFrame({'KNN':best_accuracy_knn,\n",
    "                    'KNN Normalised':best_accuracy_knn_normalised,\n",
    "                    'Bayes':accuracy_score(X_label_test, X_label_test_predicted)}.items(), columns=['Classifier', 'Accuracy'])\n",
    "print('\\n',res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see KNN Classifier when used on normalized dataset gives the best result than the other two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
